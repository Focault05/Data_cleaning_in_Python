# Data_cleaning_automation_Python
# Why data cleaning is important?
### "Better data beats fancier algorithms"
### Data cleaning ensures that the data is accurate, consistent and error free as raw data often consist of messy,missing, inconsistent, duplicates, outliers which can negatively impact the accuracy of analytics and reliability of insights derived from it.
### Useful for EDA( exploratory data analysis)

## Tools & Libraries Used
1. Python
2. Pandas
3. OS, Time, Random modules
4. Jupyter Notebook (for development)

## Implementation:-
1. Importing necessary libraries.
2. Loading the dataset and checking the file type.
3. Identifies and saves duplicate records.
4. ðŸ§¹ Removes duplicates and handles missing values.
5. Fills numeric columns with mean, if it is of int data type.
6. Drops records with missing categorical data, if it is of object data type.
7. ðŸ“ˆ Displays dataset stats: row & column count, missing data summary.
8. ðŸ’¾ Saves the cleaned dataset and duplicate records separately.

![image](https://github.com/user-attachments/assets/1a6ec07a-c3d4-4b60-9de9-ae1906df401e)

### Learnings:
1. How to make data pipelines automated and reproducible.
2. Handling real-world case study i.e how to handle missing, duplicate, null data to have clean data for better and reliable analysis.
3. Writing modular, interactive script which is easy to understand and execute.



