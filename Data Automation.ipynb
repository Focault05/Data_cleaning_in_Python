{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6085d517-bc4f-4d99-a546-4035c7837a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa405057-7d15-4bce-b90d-2bd634561e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning your dataset for better data analysis\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the path of dataset:  C:\\Users\\suman\\Downloads\\day19_sales.xlsx\n",
      "Enter name of the dataset (without extension):  2025_automation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for entering the details!\n",
      "Please wait for 1 seconds! Checking file path\n",
      "Dataset is an Excel file\n",
      "Please wait for 1 seconds! Checking rows and columns\n",
      "Dataset contains 24 rows and \n",
      "10 columns\n",
      "Dataset has 4 total duplicate records\n",
      "Total missing values in the dataset: 17\n",
      "Missing values column-wise in the dataset:\n",
      "Sales_ID          2\n",
      "Product           2\n",
      "Price             2\n",
      "Quantity          3\n",
      "Customer_ID       1\n",
      "Order_Date        2\n",
      "City              2\n",
      "Sales_Rep         0\n",
      "Discount          2\n",
      "Payment_Method    1\n",
      "dtype: int64\n",
      "Dataset is cleaned!\n",
      "Number of rows: 15 and Number of columns: 10\n",
      "Dataset is saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[col], inplace=True)  # Drop rows with nulls in object columns\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[col], inplace=True)  # Drop rows with nulls in object columns\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[col], inplace=True)  # Drop rows with nulls in object columns\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[col], inplace=True)  # Drop rows with nulls in object columns\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_29624\\669050283.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[col], inplace=True)  # Drop rows with nulls in object columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example:\n",
    "# path = r\"C:\\Users\\suman\\Downloads\\day19_sales.xlsx\"\n",
    "# name = 'random_sales_data'\n",
    "\n",
    "def data_cleaning(path, name):\n",
    "    print(\"Thank you for entering the details!\")\n",
    "    sec = random.randint(1, 5)  # generate random number\n",
    "\n",
    "    # print delay message\n",
    "    print(f\"Please wait for {sec} seconds! Checking file path\")\n",
    "    time.sleep(sec)\n",
    "\n",
    "    # checking if path exists\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Enter the correct path!\")\n",
    "        return\n",
    "    else:\n",
    "        if path.endswith('.csv'):\n",
    "            print(\"Dataset is a csv file\")\n",
    "            data = pd.read_csv(path, encoding_errors='ignore')\n",
    "        elif path.endswith('.xlsx'):\n",
    "            print(\"Dataset is an Excel file\")\n",
    "            data = pd.read_excel(path)\n",
    "        else:\n",
    "            print(\"Unknown file type\")\n",
    "            return\n",
    "\n",
    "    print(f\"Please wait for {sec} seconds! Checking rows and columns\")\n",
    "    time.sleep(sec)\n",
    "\n",
    "    # showing number of records\n",
    "    print(f\"Dataset contains {data.shape[0]} rows and \\n{data.shape[1]} columns\")\n",
    "\n",
    "    # start cleaning\n",
    "    duplicates = data.duplicated()\n",
    "    total_duplicates = duplicates.sum()\n",
    "\n",
    "    # show duplicates\n",
    "    print(f\"Dataset has {total_duplicates} total duplicate records\")\n",
    "\n",
    "    if total_duplicates > 0:\n",
    "        duplicate_records = data[duplicates]\n",
    "        # saving these records\n",
    "        duplicate_records.to_csv(f'{name}_duplicates.csv', index=None)\n",
    "\n",
    "    # deleting duplicates and storing the unique records\n",
    "    df = data.drop_duplicates()\n",
    "\n",
    "    # searching missing values\n",
    "    missing_value_columns = df.isnull().sum()  # total null column wise\n",
    "    total_missing_values = missing_value_columns.sum()\n",
    "\n",
    "    print(f\"Total missing values in the dataset: {total_missing_values}\")\n",
    "    print(f\"Missing values column-wise in the dataset:\\n{missing_value_columns}\")\n",
    "\n",
    "    # Dealing with missing values\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if df[col].dtype in (int, float):\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df.dropna(subset=[col], inplace=True)  # Drop rows with nulls in object columns\n",
    "\n",
    "    # Exporting cleaned dataset\n",
    "    print(\"Dataset is cleaned!\")\n",
    "    print(f\"Number of rows: {df.shape[0]} and Number of columns: {df.shape[1]}\")\n",
    "    df.to_csv(f'{name}_Clean_data.csv', index=None)\n",
    "    print(\"Dataset is saved successfully!\")\n",
    "\n",
    "# Ask path and file name\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Start cleaning your dataset for better data analysis\")\n",
    "    data_path = input(\"Please enter the path of dataset: \")\n",
    "    data_name = input(\"Enter name of the dataset (without extension): \")\n",
    "    data_cleaning(data_path, data_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc300c-1f39-4d3d-ae1f-d2b28562e9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa82c8-8b7e-412a-a400-e3f1d6430032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
